{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021e7a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Info (NVML): Driver Not Loaded. GPU usage metrics may not be reported. For more information, see https://docs-legacy.neptune.ai/logging-and-managing-experiment-results/logging-experiment-data.html#hardware-consumption \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/arsde/J22TAO/e/JTAO-1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Experiment(JTAO-1)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import neptune\n",
    "\n",
    "neptune.init(\n",
    "    project_qualified_name='arsde/J22TAO',\n",
    ")\n",
    "\n",
    "neptune.create_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "515d1d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JTAO-1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def init(run_name):\n",
    "    os.system('mkdir models/fcdnn_tun/{}'.format(run_name))\n",
    "    os.system('mkdir models/fcdnn_tun/{}/models_saved'.format(run_name))\n",
    "    os.system('mkdir models/fcdnn_tun/{}/results'.format(run_name))\n",
    "    \n",
    "run_name = input()\n",
    "init(run_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6c454e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.templates.default = 'plotly_white'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "570f6dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2849882516183693277\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136f5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_features = ['AccumCharge', 'rho_cc', 'pe_90p', 'R_cht', 'ht_55p',\n",
    "                'pe_mean', 'ht_5p', 'pe_80p', 'pe_std', 'pe_70p', 'nPMTs']\n",
    "\n",
    "opt_features += ['edep']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c75bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/mnt/cephfs/ml_data/TAO_detsim_J22/\"\n",
    "data = pd.read_csv(f'{path}processed_data/ProcessedTrain/ProcessedTrain.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbcf475e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1970550, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FC_cut = 0.65\n",
    "\n",
    "data = data.reset_index(drop=True)\n",
    "data = data[data['edepR'] < FC_cut][opt_features]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e294e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:, -1]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=22)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e04d79af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, concatenate, Input\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay, ExponentialDecay\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "kernel_initializer_input = ['normal', 'lecun_normal', 'uniform']\n",
    "kernel_initializer_hidden = ['normal', 'lecun_normal', 'uniform']\n",
    "activations = ['relu', 'elu', 'selu']\n",
    "optimizers = ['adam', 'rmsprop', 'SGD']\n",
    "schedules = ['None', 'ExponentialDecay']\n",
    "units_input_list = [8, 16, 32, 64, 128, 256, 512]\n",
    "units_in_hidden_layer_list = [8, 16, 32, 64, 128, 256, 512]\n",
    "num_hidden_layers_list = [4, 8, 16, 32]\n",
    "\n",
    "def build_model(hp):\n",
    "    input_features = Input(shape=X.shape[1])\n",
    "    \n",
    "    units_input = hp.Choice('units_input', units_input_list, default=128)\n",
    "    units_in_hidden_layer = hp.Choice('units_in_hidden_layer', units_in_hidden_layer_list, default=128)\n",
    "    num_hidden_layers = hp.Choice('num_hidden_layers', num_hidden_layers_list, default=8)\n",
    "    kernel_initializers_input = hp.Choice('kernel_initializers_input', kernel_initializer_input)  \n",
    "    kernel_initializers_hidden = hp.Choice('kernel_initializers_hidden', kernel_initializer_hidden)  \n",
    "\n",
    "    activation = hp.Choice('activation', values=activations)      \n",
    "    optimizer = hp.Choice('optimizer', values=optimizers)\n",
    "    \n",
    "    lr = hp.Float('lr', min_value=1e-4, max_value=1e-2, default=1e-3, sampling='LOG')\n",
    "    decay_lr = hp.Choice('decay_lr', schedules)\n",
    "        \n",
    "    batch_norm = hp.Choice('batch_norm', [False, True])\n",
    "       \n",
    "    if decay_lr == 'ExponentialDecay':\n",
    "        decay_steps = hp.Int('decay_steps', min_value=500, max_value=20000, default=2000)\n",
    "        decay_rate = hp.Float('decay_rate', min_value=0.1, max_value=0.9, default=0.8)\n",
    "\n",
    "        lr = ExponentialDecay(\n",
    "            initial_learning_rate=lr,\n",
    "            decay_steps=decay_steps,\n",
    "            decay_rate=decay_rate\n",
    "        )\n",
    "    elif decay_lr == 'CosineDecay':\n",
    "        decay_steps = hp.Int('decay_steps', min_value=500, max_value=20000, default=2000)\n",
    "\n",
    "        lr = CosineDecay(\n",
    "            initial_learning_rate=lr,\n",
    "            decay_steps=decay_steps,\n",
    "        )\n",
    "\n",
    "    x = Dense(units=units_input,\n",
    "              kernel_initializer=kernel_initializers_input,\n",
    "              activation=activation\n",
    "            )(input_features)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "\n",
    "    for i in range(num_hidden_layers):\n",
    "        x = Dense(units=units_in_hidden_layer,\n",
    "                  kernel_initializer=kernel_initializers_hidden,\n",
    "                  activation=activation\n",
    "            )(x)\n",
    "        if batch_norm:\n",
    "            x = BatchNormalization()(x)\n",
    "\n",
    "    output = Dense(units=1,\n",
    "                   kernel_initializer='normal',\n",
    "                   activation='linear')(x)\n",
    "\n",
    "    model = Model(inputs=input_features,\n",
    "                  outputs=output,\n",
    "                  name='Model')\n",
    "\n",
    "    if optimizer == 'adam':\n",
    "        beta_1 = hp.Float('beta_1', min_value=0.5, max_value=1, default=0.9,)\n",
    "        beta_2 = hp.Float('beta_2', min_value=0.5, max_value=1, default=0.999,)\n",
    "        optimizer = Adam(learning_rate=lr, beta_1=beta_1, beta_2=beta_2)\n",
    "    elif optimizer == 'rmsprop':\n",
    "        rho = hp.Float('rho', min_value=1e-1, max_value=1, default=0.9,)\n",
    "        momentum = hp.Float('momentum', min_value=0, max_value=1, default=0.9,)\n",
    "        optimizer = RMSprop(learning_rate=lr, rho=rho, momentum=momentum)\n",
    "    elif optimizer == 'SGD':\n",
    "        momentum = hp.Float('momentum', min_value=0, max_value=1, default=0.9,)\n",
    "        nesterov = hp.Boolean('nesterov', default=True)\n",
    "        optimizer = SGD(learning_rate=lr, momentum=momentum, nesterov=nesterov)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=tf.keras.losses.MeanAbsolutePercentageError(),\n",
    "        metrics=[\n",
    "                tf.keras.metrics.MeanAbsolutePercentageError(name='mape'),\n",
    "                'mse',\n",
    "                'mae'\n",
    "            ])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "752934a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5841\n",
      "INFO:tensorflow:Reloading Oracle from existing project models/fcdnn_tun/saved_networks/JTAO-1/oracle.json\n",
      "Model: \"Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 11)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1536      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 133,761\n",
      "Trainable params: 133,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import neptunecontrib.monitoring.kerastuner as npt_utils\n",
    "from kerastuner.tuners import BayesianOptimization, Hyperband\n",
    "\n",
    "\n",
    "class BayesianOptimizationBatchSize(BayesianOptimization):\n",
    "    def run_trial(self, trial, *args, **kwargs):\n",
    "        kwargs['batch_size'] = trial.hyperparameters.Int('batch_size', 128, 2048, step=64)\n",
    "        super(BayesianOptimizationBatchSize, self).run_trial(trial, *args, **kwargs)\n",
    "\n",
    "seed = np.random.randint(10000)\n",
    "print(seed)\n",
    "\n",
    "tuner = BayesianOptimizationBatchSize(\n",
    "    build_model,\n",
    "    objective='val_mape',\n",
    "    max_trials=100,\n",
    "    seed=seed,\n",
    "    directory='models/fcdnn_tun/saved_networks',\n",
    "    project_name=run_name,\n",
    "    logger=npt_utils.NeptuneLogger()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86363dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor = EarlyStopping(\n",
    "    monitor=\"val_mape\",\n",
    "    patience=10,\n",
    "    mode='min',\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7090c9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "units_input       |128               |?                 \n",
      "units_in_hidden...|512               |?                 \n",
      "num_hidden_layers |4                 |?                 \n",
      "kernel_initiali...|normal            |?                 \n",
      "kernel_initiali...|lecun_normal      |?                 \n",
      "activation        |selu              |?                 \n",
      "optimizer         |rmsprop           |?                 \n",
      "lr                |0.0049987         |?                 \n",
      "decay_lr          |None              |?                 \n",
      "batch_norm        |0                 |?                 \n",
      "beta_1            |0.92521           |?                 \n",
      "beta_2            |0.8328            |?                 \n",
      "\n",
      "Model: \"Model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 11)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1536      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 856,065\n",
      "Trainable params: 856,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "13856/13856 - 113s - loss: 1440.2979 - mape: 1440.2979 - mse: 3623507.2500 - mae: 48.3898 - val_loss: 142.0231 - val_mape: 142.0231 - val_mse: 64.8313 - val_mae: 7.5083\n",
      "Epoch 2/200\n",
      "13856/13856 - 111s - loss: 82.8345 - mape: 82.8345 - mse: 22.1277 - mae: 3.7986 - val_loss: 56.9534 - val_mape: 56.9534 - val_mse: 14.0059 - val_mae: 3.0573\n",
      "Epoch 3/200\n",
      "13856/13856 - 113s - loss: 84.0138 - mape: 84.0138 - mse: 23.5554 - mae: 3.8463 - val_loss: 67.9685 - val_mape: 67.9685 - val_mse: 9.0531 - val_mae: 2.5728\n",
      "Epoch 4/200\n"
     ]
    }
   ],
   "source": [
    "tuner.search(X_train_scaled,\n",
    "             y_train,\n",
    "             validation_data=(X_val_scaled, y_val),\n",
    "             epochs=200, \n",
    "             callbacks=[monitor],\n",
    "             verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd4d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()\n",
    "npt_utils.log_tuner_info(tuner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.get_best_models()[0]\n",
    "model.save(\"models/fcdnn_tun/{0}/models_saved/{0}.h5\".format(run_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb28099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa93d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd77e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = [0.1, 0.3, 0.6] + list(range(1, 10))\n",
    "y_true_array = []\n",
    "y_pred_array = []\n",
    "for j in tqdm(range(len(models)), \"Options...\"):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for energy in tqdm(energies):\n",
    "        test = pd.read_csv(f'{path}processed_data/ProcessedTest/{energy}MeV.csv.gz')\n",
    "        test = test[test['edepR'] < FC_cut][opt_features]\n",
    "        edep = np.array(test['edep'])\n",
    "        \n",
    "        X_test = test.iloc[:, :-1]\n",
    "        X_test = scaler.transform(X_test)\n",
    "        edep_preds = models[j].predict(X_test).flatten()\n",
    "        \n",
    "        y_true.append(edep)\n",
    "        y_pred.append(edep_preds)\n",
    "    y_true_array.append(y_true)\n",
    "    y_pred_array.append(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039bf82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eli5.permutation_importance import get_score_importances \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def score(X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    return mean_squared_error(y, y_pred)\n",
    "\n",
    "base_score, score_decreases = get_score_importances(score, X[:50000], y[:50000])\n",
    "feature_importances = np.mean(score_decreases, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4150d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = dict(zip(features_opt, feature_importances))\n",
    "fi = dict(sorted(fi.items(), key=lambda item: item[1]))\n",
    "df_fi = pd.DataFrame.from_dict(fi, orient='index', columns=['Permutation Importance'])\n",
    "df_fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287c4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptunecontrib.api import log_table\n",
    "log_table('output/permutation_importance', df_fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bca593",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = np.array([\n",
    "    [y_pred_array[j][i] - y_true_array[j][i] for i in range(len(y_pred_array[0]))]\n",
    "    for j in range(len(y_pred_array))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6675d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = [0.1, 0.3, 0.6] + list(range(1, 10))\n",
    "energies = np.array([1.022+i for i in energies]).round(5)\n",
    "energies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e786dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "a_array = []\n",
    "errors_array = []\n",
    "for k in range(diffs.shape[0]):\n",
    "    a = []\n",
    "    e = []\n",
    "    for i in range(diffs.shape[1]):\n",
    "        fig, ax = plt.subplots()\n",
    "        nbins = 150\n",
    "        n, bins, patches = ax.hist(diffs[k][i], nbins, density=True, facecolor = 'grey', alpha = 0.5, label='before');\n",
    "        plt.close(fig)\n",
    "        centers = (0.5*(bins[1:]+bins[:-1]))\n",
    "        pars, cov = curve_fit(lambda x, mu, sig : norm.pdf(x, loc=mu, scale=sig), centers, n, p0=[0,1])  \n",
    "        a.append(pars)\n",
    "        e.append(cov)\n",
    "    a_array.append(a)\n",
    "    errors_array.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa30510",
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.templates.default = 'plotly_white'\n",
    "\n",
    "for k in range(len(models)):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    for i in range(len(diffs[k])): \n",
    "        x = np.linspace(diffs[k][i][:22500].min(), diffs[k][i][:22500].max(), 100)\n",
    "        p = stats.norm.pdf(x, a_array[k][i][0], a_array[k][i][1])\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(x=x,y=p,\n",
    "                       mode='lines',\n",
    "                       name='mu={:.3f} +- {:.3f}, sigma={:.3f} +- {:.3f}'.format(\n",
    "                         a_array[k][i][0], np.sqrt(errors_array[k][i][0][0]),\n",
    "                         a_array[k][i][1], np.sqrt(errors_array[k][i][1][1])),\n",
    "                        visible = (i==0)\n",
    "                    )\n",
    "        )\n",
    "\n",
    "    for i in range(len(diffs[k])): \n",
    "        fig.add_trace(\n",
    "            go.Histogram(\n",
    "                x=diffs[k][i][:22500],\n",
    "                xbins=dict(size=0.005),\n",
    "                showlegend=False,\n",
    "                marker=dict(\n",
    "                    color='darkred',\n",
    "                    line=dict(\n",
    "                        color='black',\n",
    "                        width=2,\n",
    "                    )\n",
    "                ),\n",
    "                histnorm='probability density',\n",
    "                visible = (i==0)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    buttons = []\n",
    "    for N in range(0, len(diffs[k])): \n",
    "        buttons.append(\n",
    "            dict(\n",
    "                 args=['visible', [False]*N + [True] + [False]*(len(diffs[k])-1-N)],\n",
    "                     label='Energy =  {} MeV'.format(energies[N]),\n",
    "                 method='restyle'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    fig.update_layout(\n",
    "\n",
    "        xaxis = dict(\n",
    "            showline=True,\n",
    "            ticks='outside',\n",
    "            mirror=True,\n",
    "            linecolor='black',\n",
    "            showgrid=True,\n",
    "            gridcolor='grey',\n",
    "            gridwidth=0.25,\n",
    "        ),\n",
    "\n",
    "        yaxis = dict(\n",
    "            showline=True,\n",
    "            ticks='outside',\n",
    "            mirror=True,\n",
    "            linecolor='black',\n",
    "            tick0=0,\n",
    "    #             dtick=1,\n",
    "            showgrid=True,\n",
    "            gridcolor='grey',\n",
    "            gridwidth=0.25,\n",
    "            zeroline=True,\n",
    "            zerolinecolor='black',\n",
    "            zerolinewidth=0.25\n",
    "            ),\n",
    "    )\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=r\"$$E_{rec} - E_{true}$$\",\n",
    "    #         yaxis_title=\"y\",\n",
    "        showlegend=True,\n",
    "        updatemenus=list([\n",
    "            dict(\n",
    "                x=0.5,\n",
    "                y=1.2,\n",
    "                yanchor='top',\n",
    "                buttons=buttons\n",
    "            ),\n",
    "        ]),\n",
    "        legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.05,\n",
    "            xanchor=\"right\",\n",
    "            x=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    log_chart('output/Result_distributions.pdf', fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0074454c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(appr=False):\n",
    "    \n",
    "    fig = make_subplots(rows=2, cols=1,\n",
    "                        shared_xaxes=True,\n",
    "                        vertical_spacing=0.01,\n",
    "                        row_width=[0.25, 0.75]\n",
    "    )\n",
    "    for k in range(diffs.shape[0]):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=energies,\n",
    "                y=res[k],\n",
    "                mode='markers',\n",
    "                marker=dict(\n",
    "                    color=colors[k],\n",
    "                    symbol=symbols[k]\n",
    "                ),\n",
    "                showlegend=True,\n",
    "                error_y=dict(\n",
    "                    type='data',\n",
    "                    width=10,\n",
    "                    array=error_sigma[k],\n",
    "                    visible=True\n",
    "                ),\n",
    "                name=names[k]\n",
    "            ), row=1, col=1\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=energies,\n",
    "                y=bias[k],\n",
    "                mode='markers',\n",
    "                showlegend=False,\n",
    "                marker=dict(\n",
    "                    color=colors[k],\n",
    "                    symbol=symbols[k]\n",
    "                ),\n",
    "                error_y=dict(\n",
    "                        type='data',\n",
    "                        width=10,\n",
    "                        array=error_mu[k],\n",
    "                        visible=True\n",
    "                ),\n",
    "                name=names[k]\n",
    "            ), row=2, col=1\n",
    "        )\n",
    "\n",
    "    if appr:\n",
    "        for k in range(diffs.shape[0]):\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x_lin,\n",
    "                    y=func(x_lin, a[k], b[k], c[k]),\n",
    "                    mode='lines',\n",
    "                    line=dict(\n",
    "                    ),\n",
    "                    opacity=0.5,\n",
    "                    showlegend=False,\n",
    "                    name=names[k],\n",
    "                    marker=dict(\n",
    "                        color=colors[k]\n",
    "                    )\n",
    "                ), row=1, col=1\n",
    "            )\n",
    "\n",
    "    xaxis = dict(\n",
    "        showline=True,\n",
    "        ticks='outside',\n",
    "        mirror=True,\n",
    "        tick0=1,\n",
    "        dtick=1,\n",
    "        linecolor='black',\n",
    "        showgrid=True,\n",
    "        gridcolor='grey',\n",
    "        gridwidth=0.25,\n",
    "    )\n",
    "\n",
    "    yaxis = lambda range: dict(\n",
    "        showline=True,\n",
    "        ticks='outside',\n",
    "        mirror=True,\n",
    "        linecolor='black',\n",
    "        range=range,\n",
    "        showgrid=True,\n",
    "        gridcolor='grey',\n",
    "        gridwidth=0.25,\n",
    "        zeroline=True,\n",
    "        zerolinecolor='black',\n",
    "        zerolinewidth=0.25\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis2_title=\"Deposited energy, MeV\",\n",
    "        yaxis1_title=\"Resolution, %\",\n",
    "        yaxis2_title=\"Bias, %\",\n",
    "\n",
    "        xaxis1 = xaxis,\n",
    "        xaxis2 = xaxis,\n",
    "        yaxis1 = yaxis([0.5, 2.5]),\n",
    "        yaxis2 = yaxis([-0.3, 0.3]),\n",
    "\n",
    "        showlegend=True,\n",
    "        font=dict(\n",
    "                family=\"Times New Roman\",\n",
    "                size=18,\n",
    "        ),\n",
    "        legend=dict(\n",
    "            x=0.85,\n",
    "            y=0.99,\n",
    "            title_font_family=\"Times New Roman\",\n",
    "            font=dict(\n",
    "                family=\"Times New Roman\",\n",
    "                size=18,\n",
    "                color=\"black\"\n",
    "            ),\n",
    "            bordercolor=\"Black\",\n",
    "            borderwidth=2\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "    if appr:\n",
    "        pio.write_image(\n",
    "            fig, 'models/fcdnn_tun/{}/results/appr_results.pdf'.format(run_name),\n",
    "            width=900, height=600)\n",
    "        log_chart('{}/results/appr_results.pdf'.format(run_name), fig)\n",
    "    else:\n",
    "        pio.write_image(\n",
    "            fig, 'models/fcdnn_tun/{}/results/results.pdf'.format(run_name),\n",
    "            width=900, height=600)\n",
    "        log_chart('{}/results/results.pdf'.format(run_name), fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c066dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['royalblue']\n",
    "symbols = ['star-square']\n",
    "names = ['FCDNN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10747112",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_sigma = []\n",
    "for k in range(diffs.shape[0]):\n",
    "    error = [100 * np.sqrt(errors_array[k][i][1][1]) / energies[i] for i in range(len(energies))]\n",
    "    error_sigma.append(error)\n",
    "    \n",
    "error_mu = []\n",
    "for k in range(diffs.shape[0]):\n",
    "    error = [100 * np.sqrt(errors_array[k][i][0][0]) / energies[i] for i in range(len(energies))]\n",
    "    error_mu.append(error)\n",
    "\n",
    "res = []\n",
    "bias = []\n",
    "for k in range(diffs.shape[0]):\n",
    "    sigma = [100 * a_array[k][i][1] / energies[i] for i in range(len(energies))]\n",
    "    mu = [100 * a_array[k][i][0] / energies[i] for i in range(len(energies))]\n",
    "    res.append(sigma)\n",
    "    bias.append(mu)\n",
    "    \n",
    "plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b25235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def a(x, a):\n",
    "    return np.sqrt((a/x**0.5)**2)\n",
    "\n",
    "\n",
    "def b(x, b):\n",
    "    b_list = []\n",
    "    b_list.append(np.sqrt(b**2))\n",
    "    return b_list*len(x)\n",
    "\n",
    "\n",
    "def c(x, c):\n",
    "    return np.sqrt((c/x)**2)\n",
    "\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return np.sqrt((a/x**0.5)**2 + b**2 + (c/x)**2) \n",
    "\n",
    "\n",
    "def approximated(x, y, yerr):\n",
    "    popt, pcov = curve_fit(func, x, y, sigma=yerr, maxfev=10**8, bounds=([0, 0, 0], [5, 5, 5]))\n",
    "    a, b, c = popt\n",
    "    return func(x, a, b, c), popt, pcov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73573191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.moment_helpers import cov2corr\n",
    "\n",
    "y_approximated_array = []\n",
    "coefs_array = []\n",
    "errors_array = []\n",
    "corr_matrixes = []\n",
    "for i in range(diffs.shape[0]):\n",
    "    y_approximated, coefs, pcov = approximated(\n",
    "        energies, res[i], error_sigma[i])\n",
    "    y_approximated_array.append(y_approximated)\n",
    "    coefs_array.append(coefs)\n",
    "    errors_array.append(np.sqrt(abs(pcov.diagonal())))\n",
    "    corr_matrixes.append(cov2corr(pcov))\n",
    "\n",
    "corr_matrixes = np.array(corr_matrixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7452b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reindex = [0, 3, 1, 4, 2, 5]\n",
    "coefs_df = pd.DataFrame(\n",
    "    np.hstack((coefs_array, errors_array))\n",
    ")[reindex]\n",
    "coefs_df.columns = ['a', r'$\\Delta a$', 'b', r'$\\Delta b$', 'c', r'$\\Delta c$']\n",
    "\n",
    "a = np.array(coefs_array).T[0]\n",
    "b = np.array(coefs_array).T[1]\n",
    "c = np.array(coefs_array).T[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4260da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_lin = np.linspace(0.9, 10.1, 1000)\n",
    "plot_results(appr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566b9673",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df = coefs_df.round(3)\n",
    "coefs_df.index = names\n",
    "coefs_df[r'$\\tilde{a}$'] = np.sqrt((coefs_df['a']**2 + coefs_df['b']**2 + coefs_df['c']**2))\n",
    "coefs_df[r'$\\Delta \\tilde{a}$'] = np.sqrt(\n",
    "    coefs_df[r'$\\Delta \\tilde{a}$']**2 + 2 * (\n",
    "        coefs_df['a'] * coefs_df['b'] / coefs_df[r'$\\tilde{a}$']**2 *\\\n",
    "        corr_matrixes[:, 0, 1] * coefs_df[r'$\\Delta a$'] * coefs_df[r'$\\Delta b$'] +\\\n",
    "        \n",
    "        coefs_df['a'] * coefs_df['c'] / (coefs_df[r'$\\tilde{a}$']**2) *\\\n",
    "        corr_matrixes[:, 0, 2] * coefs_df[r'$\\Delta a$'] * coefs_df[r'$\\Delta c$'] +\\\n",
    "\n",
    "        coefs_df['b'] * coefs_df['c'] / coefs_df[r'$\\tilde{a}$']**2 *\\\n",
    "        corr_matrixes[:, 1, 2] * coefs_df[r'$\\Delta b$'] * coefs_df[r'$\\Delta c$']\n",
    "    )\n",
    ")\n",
    "coefs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f909a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_table('output/coefs_df', coefs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neptune import log_metric\n",
    "\n",
    "log_table('output/coefs_df', coefs_df)\n",
    "log_metric('a_tilde', coefs_df[r'$\\tilde{a}$']['FCDNN'])\n",
    "log_metric('a_tilde_std', coefs_df[r'$\\Delta \\tilde{a}$']['FCDNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3cf4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_df.reset_index().to_csv('models/fcdnn_tun/{}/results/params.csv'.format(run_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e69160f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
